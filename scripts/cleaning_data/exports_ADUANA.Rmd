---
title: "exports_ADUANA"
author: "Camila Vargas e Ignacia Rivera"
date: "2 de noviembre de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document cleans the Aduana exports datasets and matches the item_sa with the databease we built with aduna codes for each of the species on the SERNAPESCA datasets. 

Data was downloaded from XXX on October 8 2018.

Here the [link](http://www.aduana.cl/aduana/site/artic/20080218/pags/20080218165942.html#vtxt_cuerpo_T47) with the details of the metadata use in the exports datasets

## Setup
```{r}
library(tidyverse)
library(here)
library(readxl)
library(stringr)
library(purrr) ##install.packages("purrr")
```



## Import aduana export data

```{r}

## Create a list of files to be read

export_list <- list.files(here('information/raw_databases/ADUANAS_CHILE/exports'), pattern= 'exports_20.*.csv', full.names = TRUE)

export_list <- export_list[4:9] #select only years of interest

## Read, wrangle and bind all y datasets
exports_all <- export_list %>% 
  map(read_delim,";", escape_double = FALSE, trim_ws = TRUE, col_names = FALSE, skip =1) %>% 
  reduce(rbind) %>% 
  select(X1, X2, X5, X9, X12, X13, X14, X15, X16, X17) %>% 
  rename(year= X1, month = X2, region = X5, destination = X9, item_sa =X12, fob = X13, fub = X14, kg = X15, quantity = X16, unit = X17)
  
## Save the initial "clean raw data"
# write.csv(exports_all,  here("clean_databases/intermediate/exports_all_ADUANA.csv"), row.names=F)

```

## Data of our interest

```{r}

##sumarise data to get values per year
exports_yr <- exports_all %>% 
  select(- month, - destination, - quantity, -unit, - fub) %>%
  mutate(fob= as.numeric(sub(",", ".", fob, fixed = TRUE))) %>% 
  mutate(kg= as.numeric(sub(",", ".", kg, fixed = TRUE)))%>% 
  group_by(year, region, item_sa) %>% 
  summarise(value_fob = sum(fob, na.rm = T),
            tons = sum(kg, na.rm = T)/1000) %>% 
  ungroup() %>% 
  rename(item_sa_17 = item_sa)


# ## importing tabla de correccion to match item_sa from year previous to 2017
# correction_table <- read_excel(here('information/raw_databases/ADUANAS_CHILE/arancel_aduanero_nomenclatura/tablas_correlacion/tabla_correccion_12_17.xlsx')) %>% 
#   rename(item_sa_12= "ARANCEL 2012", item_sa_17="ARANCEL 2017") %>% 
#   filter(!is.na(item_sa_12)) %>% 
#   mutate(item_sa_12 = gsub("[.]","",item_sa_12)) %>% 
#   mutate(item_sa_17 = gsub("[.]","",item_sa_17))
# 
# 
# ##Correcting item_sa for year previous to 2017
# ## Note: parece que lo que hace el arancel aduanero del 2017 es agregar más categorías que antes no existían par los productos del 2017 en adelante! por lo tanto no hay que hacer la corresccion.  
# #Esto fue lo que hice para ver que no habian diferencias entres los item_sa del 2012 y 2017 para los años 2013, 2014, 2015 y 2016:
# 
# export_correct <- exports_yr %>% 
#   left_join(correction_table, by = "item_sa_17") 
# 
# test2 <- export_correct %>% 
#   filter(!year %in% c(2017, 2018)) %>% 
#   filter(!is.na(item_sa_12))
# setdiff(test2$item_sa_17, test2$item_sa_12)
# 
# ##Resultado: character(0)

```

## match with species SERNAPESCA data base

```{r}
## importa data set

cod_aduana_sp <- read_excel(here("information/raw_databases/ADUANAS_CHILE/arancel_aduanero_nomenclatura/arancel_aduanero_2017/codigos_aduana_por_especie_2017.xlsx"), sheet = "Hoja1", range = "A1:G756") %>%
mutate(item_sa_17 = gsub("[.]","",codigo_aduana))


##eliminar espacio previo a la especie
##hay alguna forma e leer acentos?? (al final cambiamos los acentos a mano pero seria una buea cosa aprender como poder leerlos directamente)

```

```{r}
## match accordig to "codigo aduanero" (item_sa_17)

match_exports <- exports_yr %>% 
  left_join(cod_aduana_sp, by = "item_sa_17") %>% 
  filter(!is.na(especie_SERNAPESCA)) %>% 
  group_by(year, region, especie_SERNAPESCA, nombre_cientifico_SERNAPESCA) %>% 
  summarise(tons = sum(tons, na.rm = T),
            value = sum(value_fob, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(value = ifelse(year != 2016, value/100, value))# removing two decimals cifres that were being considered as non decimal for all the years except 2016
  
##Save final and complete data base - Exports per region and species.

write.csv(match_exports,here("clean_databases/exports_ADUANA.csv"), row.names=F)

```


Matching exports with item_sa and removing items that are not for human consumption to avoid double accounting when imputing this information to the HC model. 
We assume that all products for no human consumption (oil, fish meal, agar, alginato, carragenina, colagar and dry algae) go to a facility therefor we descount this directly to the landings (see script of Scope 3)

Items SA that for the products we are removing:
Fish meal:
2301.2011
2301.2012
2301.2013
2301.2021
2301.2022
2301.2029
2301.2090
Fish oil
1603.0000 --> this item is not included in our database so we do not need to remove it.
algas secas
1212.2110
1212.2120
1212.2130
1212.2140
1212.2150
1212.2160
1212.2170
1212.2190
1212.2910
1212.2920
1212.2930
1212.2940
1212.2950
1212.2960
1212.2970
1212.2990
Agar
1302.3100


```{r}

match_exports_no_NHC <- exports_yr %>% 
  left_join(cod_aduana_sp, by = "item_sa_17") %>% 
  filter(!is.na(especie_SERNAPESCA)) %>%
  filter(!item_sa_17 %in% c("23012011", "23012012", "23012013", "23012021", "23012022", "23012029", "23012090", "12122110", "12122120", "12122130", "12122140", "12122150", "12122160", "12122170", "12122190", "12122910", "12122920", "12122930", "12122940", "12122950", "12122960", "12122970", "12122990", "13023100"))
  group_by(year, region, especie_SERNAPESCA, nombre_cientifico_SERNAPESCA) %>% 
  summarise(tons = sum(tons, na.rm = T),
            value = sum(value_fob, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(value = ifelse(year != 2016, value/100, value))
  
  

```





